En estas notas quiero escribir sobre la metodologia implementada en el trabajo de tesis.

La metodologia consta de tomar una lista que se genero en una simulacion previa montecarlo y procesarla para generar una fuente montecarlo para realizar una siguiente corrida desde esa superficie. Para hacer esto lo que hay que hacer es aproximar el espacio de fases de la lista registrada. Con esto lo que se busca es respetar la distribucion de la lista original y conservar la correlacion entre las distintas variables.

En este trabajo las variables de interes son la posicion, la direccion y la energia de los neutrones. Como la posicion es una variable vectorial, esta se representa por 3 magnitudes (xyz normalmente). La direccion es vecotrial pero en cambio es posible representarla por 2 valores. Estos siguiendo coordenadas esfericas normalmente son mu = cos theta y phi (adjuntar grafico de coordenadas esfericas). Por lo tanto normalmente se trabajaria con 6 variables, x y z mu phi E (o letargia, que es una transformacion logaritmica de E).

Sin embargo en casos especificos esta cantidad de variables disminuye. Por ejemplo en el caso desarrollado en este trabajado se ha utilizado una fuente registrada en una superficie perpendicular al eje z, por lo que esa variable queda fijada (debido a que todas las particulas registradas tienen el mismo valor de z) y entonces se trabaja con 5 variables. 

Ademas, como es de interes propagar las particulas que se generaran en la superficie hacia un lado de la misma, para el procesamiento descartamos las particulas registradas que viajan en la direccion opuesta. 

Por lo tanto de la lista original registrada trabajamos con las particulas que se propagan en la direccion de interes y nos quedamos con las 5 variables de interes (letargia, x, y, mu, phi) y una sexta que es el peso estadistico de la particula registrada, normalmente denominada weight. (adjuntar un esquemita de una lista con las 6 columnas y mostrando que tiene cientos de miles de valores).

Una vez obtenida la lista de particulas, lo que procede es elegir una variable y aproximar su distribucion mediante un histograma. Sin embargo este histograma no puede ser de bines de ancho constante debido a que en ese caso se estaria dando una representacion indistinta de la cantidad de estadistica registrada en cada intervalo de la variable. Por lo tanto lo que se busca realizar es un histograma de ancho de bines no uniforme, de modo que donde haya mayor estadistica se pueda brindar una resolucion mas fina mediante el histograma, y donde haya mas ruido estadistico se pueda dar menor resolucion. Con esto lo que se busca es poder disminuir el ruido estadistico de la lista registrada. 

Para llegar a este objetivo de obtener un histograma de bines no uniforme se ha implementado un esquema de bineado adaptativo. Este bineado adaptativo requiere que se informe la cantidad de bines totales que se buscan. Luego una fraccion de esta cantidad de bines (por ejemplo el 25%) se usan para realizar un histograma de ancho de bines uniformes para obtener una aproximacion de la distribucion gruesa, pesando las cuentas de los bines por el peso estadistico (weight) de las muestras que caen en ese bin. Luego lo que procede es obtener una CFD (cumulative frequency distribution) de la distribucion gruesa y se la compara con una CFD calculada con muchos bines (~1000) que representa la CFD medida, tambien pesada por la variable weight. Una vez obtenida ambas CFD lo que procede es realizar el valor absoluto de la resta para obtener donde se obtiene la mayor discrepancia. Entonces en ese valor se agrega un nuevo bin y se calcula una CFD de la distribucion aproximada nuevamente. Este proceso se repite hasta completar la cantidad de bines requeridos, obteniendose una distribucion de pocos bines adaptativa debido a que los mismos se concentran donde hay mayor estadistica y por lo tanto mayor diferencia. (agregar un esquema de la dsitribucion y CFD con pocos bines (ese 25%) comparando con 1000 bines. Mostrar el valor absoluto de la diferencia e indicar donde caeria el nuevo bin. Luego mostrar la distribucion y CFD obtenida luego de finalizar el bineado adaptativo). Con esto lo que se obtiene es la aproximacion de la distribucion micro de la variable en cuestion, que va a ser lo que se utilice para luego generar un valor de esta variable en el proceso de resampleo.

Con el procedimiento anterior se logra obtener la informacion necesaria para generar una particula que respete la distribucion de esa variable segun el set de datos original. Lo que procede es establecer la estrategia para conservar la correlacion de la primer variable seleccionada con respecto de las otras variables. Para lograr esto se divide el set de datos original en N subconjuntos. Con esto se busca separar al set de datos en subconjuntos que tengan un comportamiento similar en el resto de las variables. Con este objetivo se divide la primer variable del set de datos original en 4 subconjuntos, obteniendose asi una aproximacion gruesa. Luego siguiendo el esquema adaptativo (utilizado en la aproximacion de la distribucion de la primer variable) se agregan bordes de grupos adicionales de forma secuencial hasta obtener la cantidad de macrogrupos M seleccionada por el usuario. Este proceso ha mostrado poder encontrar los cambios bruscos de la distribucion y poder separar conjuntos de particulas que obedecen un comportamiento distinto. Esto es util para evitar diluir las correlaciones de las variables. 

Una vez obtenido los macrogrupos, se procesa con este mismo procedimiento cada uno de los subconjuntos obtenidos, pero enfocandonos en la siguiente variable. Este proceso se repite hasta llegar hasta la ultima variable. Con esto se obtiene un arbol donde en cada nodo existe la distribucion acumulada obtenida con los microgrupos y los bordes de los macrogrupos. Y de cada nodo surgen M nodos correspondiente a los macrogrupos de la variable del nodo. Es eleccion del usuario con cuantos macrogrupos se va a dividir cada variable y en que orden se van a procesar las mismas. 

Este proceso no es muy demandante en terminos computacionales, por lo que es viable realizarlo en python, como se ha hecho. Por lo tanto se creo una rutina que permite tomar un archivo registrado de una simulacion montecarlo y aplicarle esta metodologia segun el input del usuario de la cantidad de macrogrupos, microgrupos, orden de las variables y, de forma opcional, bordes de macrogrupos que el usuario quiera introducir de forma manual. Esto es util para poder mejorar la estimacion si se conocen ciertos limites que separan subconjuntos de particulas que no tienen variables correlacionadas. En este caso se divide primero de forma gruesa en 4 subconjuntos y el proximo en agregarse es el seleccionado por el usuario, y a posteriori se seleccionan los siguientes bordes utilizando el metodo adaptativo.

Una vez obtenido el arbol con la aproximacion de la distribucion y la correlacion de las variables es necesario guardar esa informacion en disco. Esto se hace para poder utilizar este archivo como fuente de la siguiente simulacion montecarlo en OpenMC. Para esto se ha agregado en el codigo fuente un tipo de fuente ad hoc para generar fuentes utilizando el arbol de histogramas multidimensionales. 

Debido a la naturaleza de los datos en estructura tipo arbol, un tipo de lenguaje optimo es el formato XML. Por lo tanto se guarda la informacion generada en python en formato XML.

La implementacion que se realizo en openmc se ha realizado en la API de python y en el codigo fuente en C++. Se ha modificado la API para poder indicarle el tipo de fuente nuevo y mandarle como parametro la direccion del archivo XML. Luego OpenMC carga el archivo XML en estructuras de datos ad hoc, obteniendo los histogramas multidimensionales y otras variables extras necesarias para el correcto resampleo. Luego utilizando el modulo histograms creado ad hoc en KDSource es posible generar una particula. 

El proceso de generar una particula consta en generar un numero pseudoaleatorio entre 0 y 1. Con este numero se interpola la CFD de la primer variable y se obtiene un valor de la primer variable. Se utiliza primero la primer variable porque es el root node de los histogramas multidimensionales. Luego se busca a que macrogrupo corresponde ese valor sampleado y se procede a repetir el proceso utilizando la informacion de ese subconjunto de datos. Este proceso significa avanzar por una rama en el arbol de histogramas multidimensionales.

Una vez obtenida la particula OpenMC simula la vida de esa particula. Al generar las particulas una por una, no es necesario generar una lista de forma previa y despues correrla. Esto reduce el requerimiento de tener que cargar todas las particulas en memoria ram a la hora de correr la simulacion en OpenMC utilizando el tipo de fuente SourceFile implementado previamente. Esto hace que la experiencia a la hora de utilizar la herramienta implementada sea mas sencilla. 

