\chapter{Metodología para la Generación de Fuentes Monte Carlo Mediante Histogramas Multidimensionales}

\section{Introducción general al método}
La metodología propuesta se basa en la utilización de \emph{trackfiles} generados en simulaciones Monte Carlo previas, específicamente usando OpenMC, para definir fuentes en simulaciones subsiguientes. Esta técnica se enmarca dentro de los métodos de reducción de varianza conocidos como \textit{Source Biasing}.

\section{Definición del espacio de fases \texorpdfstring{$(\mathbf{E}$--$\mathbf{r}$--$\boldsymbol{\Omega})$}{(E--r--Omega)}}
Para aproximar correctamente el espacio de fases se consideraron seis variables para representar la energía, posición y dirección: tres coordenadas espaciales $(x, y, z)$, dos variables direccionales definidas en coordenadas esféricas ($\mu = \cos(\theta), \phi$) y una variable energética ($E$ o letargia, definida como una transformación logarítmica de la energía). En situaciones específicas, tales como la utilizada en esta tesis donde se registra la fuente en una superficie perpendicular al eje $z$, se reduce a cinco variables, ya que la coordenada $z$ permanece constante.

\textbf{Figura:} Diagrama de coordenadas esféricas mostrando cómo se definen las variables direccionales $\mu$ y $\phi$.

\section{Procesamiento del \emph{trackfile} original}
Inicialmente, las partículas provenientes de la simulación Monte Carlo original se filtran seleccionando únicamente aquellas que se propagan hacia la región de interés y se separan las variables relevantes mencionadas, además del peso estadístico (\textit{weight}).

\textbf{Figura:} Tabla o esquema ilustrando la estructura de la lista de partículas (\textit{letargia, x, y, $\mu$, $\phi$, weight}), indicando que contiene cientos de miles de entradas.

\section{Aproximación de distribuciones mediante histogramas}

Las distribuciones continuas de las variables en el espacio de fases pueden representarse, de forma general, mediante histogramas. La elección del método de discretización (bineado) es crucial y condiciona la calidad de la aproximación obtenida. Los tres esquemas de bineado utilizados en este trabajo son:

\begin{itemize}
    \item \textbf{bineado de igual separación}: Divide el rango completo de la variable en intervalos de ancho constante. 

    \item \textbf{bineado de igual integral}: Divide el rango en intervalos que contienen aproximadamente la misma cantidad de peso estadístico, generando así bines de tamaño variable. Este método logra una representación más eficiente en términos estadísticos, especialmente en regiones donde la densidad cambia abruptamente.

    \item \textbf{bineado adaptativo}: Divide el rango utilizando una discretización iterativa que asigna mayor resolución a las zonas de alta densidad estadística y menor resolución en regiones escasamente pobladas, con el objetivo explícito de reducir el ruido estadístico manteniendo manteniendo resolución en los cambios abruptos de la distribución.
\end{itemize}

En este trabajo se profundiza particularmente sobre el método de bineado adaptativo. El procedimiento adaptativo propuesto se realiza en dos etapas principales:

\begin{enumerate}
    \item \textbf{Aproximación inicial gruesa}: Se discretiza la distribución con una cantidad reducida de bines uniformemente distribuidos, típicamente utilizando cerca del 25\% del número final previsto de bines.
    
    \item \textbf{Refinamiento iterativo}: En cada iteración se evalúa la diferencia absoluta entre la distribución acumulada estimada (CDF aproximada mediante los bines actuales) y la distribución acumulada de referencia (calculada con muchos bines). Se agregan bines adicionales precisamente en las regiones donde esta diferencia es máxima, mejorando progresivamente la calidad del histograma resultante.
\end{enumerate}

Esta estrategia adaptativa permite capturar adecuadamente las regiones críticas de la distribución, proporcionando un balance controlado entre resolución local y suavidad global.

% \section{Aproximación de distribuciones mediante histogramas adaptativos}
% La distribución de cada variable es representada mediante histogramas con bines de ancho no uniforme, seleccionados mediante una técnica de \textit{binning} adaptativo. Este procedimiento asigna mayor resolución a regiones del espacio de fases con mayor densidad estadística y menor resolución en regiones de baja estadística, con el fin de reducir el ruido estadístico.

% El proceso adaptativo se realiza en dos etapas principales:
% \begin{enumerate}
%     \item Una aproximación gruesa con una cantidad inicial de bines uniformes (aproximadamente el 25\% del total).
%     \item Ajuste iterativo agregando nuevos bines donde la diferencia absoluta entre la distribución acumulada estimada (CFD) y la distribución acumulada real (calculada con un gran número de bines) es mayor.
% \end{enumerate}

\textbf{Figura:} Esquema gráfico del procedimiento de \textit{binning} adaptativo, mostrando claramente las distribuciones estimadas con pocos bines, la distribución real y la diferencia absoluta utilizada para definir nuevos bines.

\section{Mantenimiento de correlaciones mediante macrogrupos}

El algoritmo desarrollado permite preservar las correlaciones entre variables del espacio de fases a través de divisiones sucesivas del conjunto de datos. Este proceso admite tres esquemas posibles de bineado para cada variable: de igual separación, de igual integral o adaptativo. En todos los casos, la variable considerada se utiliza para dividir el conjunto de partículas actual en subgrupos o \emph{macrogrupos}, que son luego tratados recursivamente.

Particularmente, en el caso del binning adaptativo, el procedimiento comienza con una partición inicial de baja resolución —usualmente cuatro macrogrupos— y se aplica un refinamiento iterativo utilizando un criterio similar al empleado en la sección anterior: se identifican las regiones donde la separación entre la distribución acumulada empírica y la distribución acumulada de referencia es mayor, y se subdividen esas regiones para aumentar la resolución local.

Este proceso de partición se aplica a cada variable en un orden definido por el usuario, generando una estructura en forma de árbol. En cada nodo del árbol se almacena la distribución acumulada de la variable correspondiente a ese nivel, junto con las fronteras de los macrogrupos definidos. Esta estructura permite preservar las correlaciones multidimensionales entre variables, ya que cada división se realiza condicionada a las divisiones previas.


% \section{Mantenimiento de correlaciones mediante macrogrupos}
% Para preservar la correlación entre variables, se utiliza una estrategia basada en la división secuencial del conjunto de datos en macrogrupos, comenzando con una división gruesa en cuatro subconjuntos y luego refinándola iterativamente mediante el procedimiento adaptativo hasta alcanzar la cantidad deseada de macrogrupos.

% Este proceso jerárquico y secuencial se aplica iterativamente a cada una de las variables del espacio de fases, dando lugar a una estructura de árbol donde cada nodo contiene información sobre la distribución acumulada de la variable correspondiente.

\textbf{Figura:} Esquema ilustrando la estructura jerárquica de macrogrupos y microgrupos formando un árbol, resaltando claramente la jerarquía de variables.

\section{Implementación computacional}
La metodología descrita ha sido implementada en Python, debido a su leve/moderado costo computacional, creando una rutina que permite configurar parámetros tales como el número de macrogrupos, microgrupos, estilo de bineado de macrogrupos y microgrupos y orden de procesamiento de las variables. Esta rutina también ofrece la opción de insertar bordes manuales de macrogrupos cuando se dispone de información previa que optimice la estimación.

La estructura generada (árbol jerárquico de histogramas multidimensionales) es almacenada en un archivo XML, formato ideal debido a la estructura tipo árbol del dato generado. Posteriormente, esta información es utilizada directamente como fuente en simulaciones Monte Carlo subsecuentes en OpenMC, mediante modificaciones específicas realizadas tanto en su API de Python como en su código fuente en C++.

\section{Remuestreo de partículas en simulaciones Monte Carlo subsecuentes}
El proceso de generación de partículas a partir de la distribución guardada implica:
\begin{enumerate}
    \item Generar un número pseudoaleatorio entre 0 y 1.
    \item Interpolar dicho número en la distribución acumulada normalizada de la variable raíz del árbol.
    \item Avanzar secuencialmente por las ramas del árbol determinando valores de las variables subsecuentes hasta obtener un conjunto completo de variables del espacio de fases.
\end{enumerate}

Este enfoque evita la necesidad de cargar grandes listas en memoria RAM durante la ejecución de simulaciones Monte Carlo, lo que simplifica considerablemente el manejo de fuentes en OpenMC.

Este enfoque permite generar partículas para una siguiente simulación Monte Carlo. Existen dos formas de integrar esta funcionalidad con OpenMC:

\begin{itemize}
    \item Una opción consiste en realizar, de forma \emph{off-line}, el muestreo de una cantidad predeterminada de partículas y guardar sus propiedades en un archivo tipo trackfile. Este archivo puede ser luego utilizado por OpenMC mediante su opción de simulación desde lista de partículas preexistente.
    
    \item Alternativamente, se puede ejecutar OpenMC con una fuente del tipo \texttt{HistogramSource}, definida ad hoc y configurada mediante un archivo XML. En este caso, OpenMC accede directamente al árbol de histogramas durante la simulación y genera cada partícula \emph{on-the-fly}, lo que reduce significativamente el uso de memoria y evita la necesidad de almacenar archivos intermedios voluminosos.
\end{itemize}

\section{Conexión con la implementación computacional}
La metodología expuesta será implementada mediante códigos desarrollados en Python, C y C++, integrados específicamente dentro de los entornos de simulación Monte Carlo OpenMC y KDSource. La implementación detallada y comentada de estos códigos se presenta en el Anexo A, mostrando de forma explícita cómo se lleva a la práctica el proceso descrito anteriormente.

En los capítulos siguientes el desempeño del método descrito será evaluado para cuantificar el grado en que el método conserva las propiedades originales del conjunto de partículas registrado.
